"""
ÃNDICE DE ARCHIVOS ETL
======================

Este archivo documenta todos los archivos creados para el ETL.
"""

# ESTRUCTURA COMPLETA DEL ETL
# ============================

ARCHIVOS_CREADOS = {
    
    # ====== CORE ETL ======
    "src/etl_football_data.py": {
        "descripciÃ³n": "Pipeline ETL principal (3 clases principales)",
        "lÃ­neas": "~1200",
        "clases": [
            "FootballDataExtractor - Descarga desde Football-Data.co.uk",
            "FootballDataTransformer - Normaliza y enriquece datos",
            "FootballDataLoader - Carga en SQLite/PostgreSQL",
            "FootballETLPipeline - Orquesta todo el pipeline"
        ],
        "mÃ©todos_clave": [
            "ejecutar() - Run completo del pipeline",
            "descargar_csv() - Descarga un archivo CSV",
            "transformar() - Pipeline de transformaciÃ³n",
            "cargar_datos() - Inserta en BD"
        ]
    },
    
    # ====== CLI ======
    "src/etl_cli.py": {
        "descripciÃ³n": "Interfaz CLI para ejecutar ETL",
        "lÃ­neas": "~500",
        "comandos": [
            "run - Ejecutar pipeline completo",
            "stats - Ver estadÃ­sticas de datos cargados",
            "validate - Validar integridad de BD",
            "export - Exportar datos a mÃºltiples formatos"
        ],
        "usar": "python etl_cli.py run"
    },
    
    # ====== CONFIGURACIÃ“N ======
    "src/etl_config.py": {
        "descripciÃ³n": "ConfiguraciÃ³n centralizada",
        "lÃ­neas": "~150",
        "contiene": [
            "DATABASE_CONFIG - Configs SQLite/PostgreSQL",
            "ETL_CONFIG - ParÃ¡metros de descarga",
            "LIGAS_CONFIG - DefiniciÃ³n de ligas",
            "Validaciones automÃ¡ticas"
        ]
    },
    
    # ====== ANÃLISIS ======
    "src/etl_data_analysis.py": {
        "descripciÃ³n": "AnÃ¡lisis y queries sobre datos",
        "lÃ­neas": "~600",
        "clases": [
            "FootballDataAnalyzer - Queries y estadÃ­sticas",
            "FootballDataExporter - Exporta a varios formatos",
            "FootballDataValidator - Valida calidad de datos"
        ],
        "mÃ©todos": [
            "obtener_estadisticas_equipo() - Stats completas",
            "calcular_probabilidades_match() - Poisson",
            "obtener_enfrentamientos_directos() - H2H",
            "obtener_top_equipos() - Ranking por mÃ©trica"
        ]
    },
    
    # ====== EJEMPLOS ======
    "examples.py": {
        "descripciÃ³n": "Ejemplos de uso de todos los mÃ³dulos",
        "lÃ­neas": "~600",
        "ejemplos": [
            "1. Descargar datos",
            "2. Analizar equipo",
            "3. Historial directo (H2H)",
            "4. Predecir partido",
            "5. Top equipos",
            "6. Tendencias de mercado",
            "7. Exportar para ML",
            "8. Validar datos"
        ],
        "usar": "python examples.py descargar_datos"
    },
    
    # ====== DOCUMENTACIÃ“N ======
    "docs/ETL_FOOTBALL_DATA_GUIDE.md": {
        "descripciÃ³n": "GuÃ­a completa (6000+ palabras)",
        "secciones": [
            "DescripciÃ³n general",
            "CaracterÃ­sticas principales",
            "InstalaciÃ³n",
            "Uso (CLI, Python, mÃ³dulos)",
            "ConfiguraciÃ³n BD",
            "Esquema de BD",
            "Estructura de datos",
            "Casos de uso",
            "Troubleshooting",
            "Ejemplos completos"
        ]
    },
    
    "ETL_QUICKSTART.md": {
        "descripciÃ³n": "GuÃ­a rÃ¡pida (empezar en 5 minutos)",
        "contiene": [
            "TL;DR",
            "Comandos principales",
            "Ejemplos Python",
            "Troubleshooting bÃ¡sico",
            "Checklist"
        ]
    },
    
    # ====== MODIFICACIONES ======
    "requirements.txt": {
        "descripciÃ³n": "Actualizado con todas las dependencias",
        "agregadas": [
            "sqlalchemy>=2.0.0",
            "psycopg2-binary>=2.9.0",
            "python-dotenv>=1.0.0",
            "pyarrow>=12.0.0"
        ]
    }
}


# ARQUITECTURA DEL PIPELINE
# ==========================

"""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FOOTBALL DATA ETL                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ENTRADA: Football-Data.co.uk (CSV)                        â”‚
â”‚           â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  FASE 1: EXTRACCIÃ“N                  â”‚                 â”‚
â”‚  â”‚  FootballDataExtractor               â”‚                 â”‚
â”‚  â”‚  â€¢ 3 ligas Ã— 10 temporadas           â”‚                 â”‚
â”‚  â”‚  â€¢ Reintentos automÃ¡ticos            â”‚                 â”‚
â”‚  â”‚  â€¢ Rate limiting                     â”‚                 â”‚
â”‚  â”‚  â€¢ ~30 archivos CSV                  â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚           â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  FASE 2: TRANSFORMACIÃ“N              â”‚                 â”‚
â”‚  â”‚  FootballDataTransformer             â”‚                 â”‚
â”‚  â”‚  â€¢ NormalizaciÃ³n de fechas (ISO)     â”‚                 â”‚
â”‚  â”‚  â€¢ SelecciÃ³n de columnas crÃ­ticas    â”‚                 â”‚
â”‚  â”‚  â€¢ ValidaciÃ³n y limpieza             â”‚                 â”‚
â”‚  â”‚  â€¢ Enriquecimiento (derived cols)    â”‚                 â”‚
â”‚  â”‚  â€¢ ~10,500 registros                 â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚           â†“                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚  FASE 3: CARGA                       â”‚                 â”‚
â”‚  â”‚  FootballDataLoader                  â”‚                 â”‚
â”‚  â”‚  â€¢ SQLite (desarrollo)               â”‚                 â”‚
â”‚  â”‚  â€¢ PostgreSQL (producciÃ³n)           â”‚                 â”‚
â”‚  â”‚  â€¢ InserciÃ³n masiva en chunks        â”‚                 â”‚
â”‚  â”‚  â€¢ Ãndices automÃ¡ticos               â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚           â†“                                                 â”‚
â”‚  SALIDA: Base de Datos Limpia y Normalizada               â”‚
â”‚          â€¢ Listo para predicciÃ³n                          â”‚
â”‚          â€¢ Listo para anÃ¡lisis                            â”‚
â”‚          â€¢ Listo para entrenamiento ML                    â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
"""


# FLUJO DE DATOS
# ==============

"""
ANTES (Sin ETL):
â”œâ”€â”€ Datos crudos de API
â”œâ”€â”€ Formatos inconsistentes
â”œâ”€â”€ Fechas en mÃºltiples formatos
â”œâ”€â”€ Columnas faltantes
â””â”€â”€ âŒ No apto para predicciÃ³n

DESPUÃ‰S (Con ETL):
â”œâ”€â”€ Datos descargados automÃ¡ticamente
â”œâ”€â”€ Formato normalizado (ISO 8601)
â”œâ”€â”€ Columnas crÃ­ticas preservadas
â”œâ”€â”€ Valores enriquecidos
â”œâ”€â”€ ValidaciÃ³n automÃ¡tica
â””â”€â”€ âœ… Listo para predicciÃ³n + ML
"""


# CASOS DE USO
# ============

CASOS_USO = {
    
    "1. PREDICCIÃ“N": {
        "descripciÃ³n": "Usar datos histÃ³ricos para predicciÃ³n",
        "pasos": [
            "1. python etl_cli.py run",
            "2. from src.etl_data_analysis import FootballDataAnalyzer",
            "3. analyzer.calcular_probabilidades_match('team1', 'team2')",
            "4. Ver probabilidades en Streamlit"
        ]
    },
    
    "2. MACHINE LEARNING": {
        "descripciÃ³n": "Crear dataset para entrenar modelos",
        "pasos": [
            "1. python etl_cli.py run",
            "2. python etl_cli.py export --output training_data.parquet",
            "3. Importar en scikit-learn/XGBoost/TensorFlow",
            "4. Entrenar modelo predictivo"
        ]
    },
    
    "3. ANÃLISIS EXPLORATORIO": {
        "descripciÃ³n": "Analizar equipos y tendencias",
        "pasos": [
            "1. python etl_cli.py run",
            "2. python examples.py analizar_equipo 'Liverpool'",
            "3. python examples.py top_equipos",
            "4. python examples.py h2h 'team1' 'team2'"
        ]
    },
    
    "4. DASHBOARD": {
        "descripciÃ³n": "Visualizar datos en Streamlit",
        "pasos": [
            "1. python etl_cli.py run",
            "2. Importar FootballDataAnalyzer en app.py",
            "3. Mostrar grÃ¡ficos y estadÃ­sticas",
            "4. streamlit run src/app.py"
        ]
    },
    
    "5. SISTEMA EN PRODUCCIÃ“N": {
        "descripciÃ³n": "Desplegar con datos actualizados",
        "pasos": [
            "1. Usar PostgreSQL (no SQLite)",
            "2. Ejecutar ETL en schedule (cron)",
            "3. Validar datos automÃ¡ticamente",
            "4. Entrenar modelos con nuevos datos"
        ]
    }
}


# LIGAS SOPORTADAS
# ================

LIGAS = {
    "E0": {
        "nombre": "Premier League",
        "paÃ­s": "Inglaterra",
        "partidos/temporada": 380,
        "temporadas": 10
    },
    "SP1": {
        "nombre": "La Liga",
        "paÃ­s": "EspaÃ±a",
        "partidos/temporada": 380,
        "temporadas": 10
    },
    "D1": {
        "nombre": "Bundesliga",
        "paÃ­s": "Alemania",
        "partidos/temporada": 306,
        "temporadas": 10
    }
}

# Total: ~10,500 partidos histÃ³ricos


# COLUMNAS DE BD
# ==============

COLUMNAS = {
    "temporales": ["date", "temporada"],
    "equipos": ["home_team", "away_team"],
    "resultado": ["fthg", "ftag", "ftr", "total_goles"],
    "tiros": ["hs", "as_shots", "hst", "ast", "diff_tiros"],
    "disciplina": ["hf", "af", "hr", "ar", "hy", "ay"],
    "cuotas": ["b365h", "b365d", "b365a"],
    "derivadas": ["over_25", "efectividad_local"],
    "metadata": ["created_at"]
}


# PERMISOS Y REQUIERE
# ===================

REQUISITOS = {
    "extracciÃ³n": {
        "internet": "âœ“ Necesaria (descarga de datos)",
        "api_key": "âœ— No necesaria (datos pÃºblicos)",
        "limite": "Respetuoso con rate limits (1s entre descargas)"
    },
    
    "transformaciÃ³n": {
        "ram": "~2GB para 10,500 registros",
        "cpu": "Bajo (operaciones simples)",
        "tiempo": "~5-10 minutos (incluye descargas)"
    },
    
    "carga": {
        "sqlite": "âœ“ AutomÃ¡tico (no instalaciÃ³n)",
        "postgresql": "Requiere instalaciÃ³n + credenciales"
    }
}


# VENTAJAS vs DESVENTAJAS
# =======================

VENTAJAS = [
    "âœ… Descarga automatizada (sin APIKey)",
    "âœ… Datos limpios y validados",
    "âœ… 10 aÃ±os de histÃ³rico",
    "âœ… MÃºltiples ligas",
    "âœ… Columnas crÃ­ticas para predicciÃ³n",
    "âœ… Flexible (SQLite/PostgreSQL)",
    "âœ… AnÃ¡lisis integrado",
    "âœ… ExportaciÃ³n mÃºltiple",
    "âœ… Logging completo",
    "âœ… Ejemplos de uso"
]

LIMITACIONES = [
    "âš ï¸ Descarga inicial: 5-10 minutos",
    "âš ï¸ Datos histÃ³ricos (no en vivo)",
    "âš ï¸ 10 temporadas mÃ¡ximo (Football-Data)",
    "âš ï¸ Requiere almacenamiento (~200MB SQLite)"
]


# ROADMAP FUTURO
# ==============

ROADMAP = [
    "[ ] Descarga incremental (solo nuevos partidos)",
    "[ ] CachÃ© de descargas",
    "[ ] IntegraciÃ³n con API en vivo",
    "[ ] MÃ¡s ligas (Serie A, Ligue 1, etc)",
    "[ ] Predicciones en tiempo real",
    "[ ] Dashboard web (Flask/FastAPI)",
    "[ ] Alertas de cambios en cuotas",
    "[ ] ExportaciÃ³n a Cloud (BigQuery, Redshift)"
]


# CONTACTO Y SOPORTE
# ==================

SOPORTE = {
    "documentaciÃ³n": "docs/ETL_FOOTBALL_DATA_GUIDE.md",
    "quick_start": "ETL_QUICKSTART.md",
    "ejemplos": "examples.py",
    "logs": "logs/etl_football_data.log",
    "issues": "GitHub Issues (proyectotimba)"
}


if __name__ == "__main__":
    print("\n" + "="*70)
    print("ğŸ“‹ ÃNDICE ETL FOOTBALL DATA")
    print("="*70)
    
    print("\nğŸ“ ARCHIVOS PRINCIPALES:")
    for archivo, info in ARCHIVOS_CREADOS.items():
        print(f"\n  {archivo}")
        print(f"    ğŸ“ {info.get('descripciÃ³n', 'N/A')}")
        print(f"    ğŸ“Š {info.get('lÃ­neas', 'N/A')} lÃ­neas")
    
    print("\n\nğŸ“‹ CASOS DE USO:")
    for caso, detalles in CASOS_USO.items():
        print(f"\n  {caso}")
        print(f"    {detalles['descripciÃ³n']}")
    
    print("\n\nâœ… VENTAJAS:")
    for v in VENTAJAS:
        print(f"  {v}")
    
    print("\n\nâš ï¸ LIMITACIONES:")
    for l in LIMITACIONES:
        print(f"  {l}")
    
    print("\n" + "="*70)
    print("âœ¨ ETL listo para usar!")
    print("="*70 + "\n")
